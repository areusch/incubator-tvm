------------------- Graph -------------------
{
  "nodes": [
    {
      "op": "null", 
      "name": "data", 
      "inputs": []
    }, 
    {
      "op": "tvm_op", 
      "name": "fused_layout_transform_2", 
      "attrs": {
        "func_name": "fused_layout_transform_2", 
        "flatten_data": "0", 
        "num_inputs": "1", 
        "num_outputs": "1"
      }, 
      "inputs": [
        [
          0, 
          0, 
          0
        ]
      ]
    }, 
    {
      "op": "null", 
      "name": "p0", 
      "inputs": []
    }, 
    {
      "op": "tvm_op", 
      "name": "fused_nn_contrib_conv2d_NCHWc_right_shift_cast", 
      "attrs": {
        "func_name": "fused_nn_contrib_conv2d_NCHWc_right_shift_cast", 
        "flatten_data": "0", 
        "num_inputs": "2", 
        "num_outputs": "1"
      }, 
      "inputs": [
        [
          1, 
          0, 
          0
        ], 
        [
          2, 
          0, 
          0
        ]
      ]
    }, 
    {
      "op": "tvm_op", 
      "name": "fused_layout_transform_1", 
      "attrs": {
        "func_name": "fused_layout_transform_1", 
        "flatten_data": "0", 
        "num_inputs": "1", 
        "num_outputs": "1"
      }, 
      "inputs": [
        [
          3, 
          0, 
          0
        ]
      ]
    }
  ], 
  "arg_nodes": [0, 2], 
  "heads": [
    [
      4, 
      0, 
      0
    ]
  ], 
  "attrs": {
    "dltype": [
      "list_str", 
      [
        "uint8", 
        "uint8", 
        "int8", 
        "int8", 
        "int8"
      ]
    ], 
    "storage_id": [
      "list_int", 
      [0, 1, 2, 3, 1]
    ], 
    "shape": [
      "list_shape", 
      [
        [1, 3, 64, 64], 
        [1, 1, 64, 64, 3], 
        [1, 1, 5, 5, 3, 8], 
        [1, 1, 64, 64, 8], 
        [1, 8, 64, 64]
      ]
    ]
  }, 
  "node_row_ptr": [0, 1, 2, 3, 4, 5]
}
-------------------- AOT --------------------
#include <inttypes.h>
#include <dlpack/dlpack.h>
const int8_t p0_param_data[600] = {
96, -100, 87, -106, -45, -23, 52, -76, 5, 107, 11, 123, 6, -78, 110, -58, 101, 123, 24, -4, 10, 70, -61, 16, -50, -56, -43, -121, 8, 127, -72, 42, 120, 39, -16, 78, -30, 28, 117, 114, -6, 59, 9, 25, 12, -51, -43, -81, -77, -32, 70, -15, 4, 97, 125, 56, 62, -118, 127, -5, 113, -27, -116, 26, 62, -90, -15, -126, 108, 15, 77, -75, 42, 93, 86, 20, 89, 58, -110, 48, 110, 30, 107, 44, 63, 13, 31, -32, -116, 19, 126, -128, -83, 29, 111, 54, 88, 98, -5, -113, 27, 40, 83, -95, 124, -92, 101, 49, 43, 103, -72, -60, 107, -25, 24, -9, -72, -26, -107, 49, 50, 60, 93, 107, 112, -34, -118, 19, -108, 62, 93, -33, 91, 25, -44, 6, -46, 27, -43, 117, -58, -20, 12, 67, -21, 92, 85, 27, -65, 65, -52, -54, 71, 3, -47, 42, 37, -8, -2, -38, 43, 36, 117, 9, -114, 42, -22, -26, -123, 84, -24, 70, -82, -92, 98, 89, 115, -50, -23, 105, 5, 15, -73, -2, 79, -74, -91, 81, -36, 14, 106, -72, 112, 32, 8, 95, -125, 63, -77, 4, 87, -35, 66, 110, 2, -100, -65, 7, 84, 115, -75, 86, 44, -29, 45, -40, -101, 59, 9, -69, 90, 124, -8, -11, -108, -74, 83, 81, -62, -7, 39, -56, 66, -22, 46, 12, -118, 24, 108, -93, -20, 4, 78, 112, -34, 115, 91, 67, 8, 24, 113, 83, 87, -58, -15, 114, 35, -4, -111, 82, -91, 102, 81, 17, 61, 105, 65, 103, -21, -31, -99, -39, 64, -6, -1, 38, -67, -30, 51, 93, 32, -98, -15, -65, -91, 11, 111, 8, 6, -100, 58, -119, 56, -32, -41, -88, 73, 17, -111, -86, 58, 14, -128, -47, 1, 2, 103, -40, -55, -6, -91, -116, -38, 114, -80, -80, -32, 75, -47, 17, -45, 64, -103, 59, 85, -73, -92, 117, -61, -15, 3, -52, -65, 48, 3, -112, -50, -13, 34, -26, -119, 96, -63, -9, -86, -103, 37, -108, -113, -26, -43, -5, -50, -112, 53, -96, 92, 58, 97, 85, -90, 68, 97, 24, 45, 78, -57, 40, -64, -123, -4, 79, -57, -122, 14, -127, 67, 70, 120, -67, -20, 63, -119, 1, -40, 121, 58, -52, 122, 102, 59, -59, 94, 72, -28, -88, -69, -66, 77, -87, -37, 123, 47, -107, 92, 78, 74, 92, -126, -117, -74, 34, 92, -21, -101, 93, 115, 37, -43, 60, -6, -61, 80, 15, -6, -92, -82, -75, 10, 69, 73, 100, -49, 5, -16, -15, -15, -44, -108, -49, 42, 112, 55, -61, 55, -124, 73, 104, -119, -101, 58, -19, -51, 89, -74, -25, -74, -67, 76, -102, -3, -62, -46, 16, 110, -85, -75, 79, -86, 38, 41, -76, 31, -65, 79, -14, 6, 64, 66, 117, -93, -110, 36, 24, -78, 75, -80, -105, 19, -120, -37, 74, -72, 27, -64, -96, -13, -88, 4, -2, 114, 95, -43, -67, -18, -58, 29, -103, 86, 63, -55, -100, 68, -72, 122, 66, 46, -55, 70, -110, 8, -64, 85, -77, -113, 104, -113, 80, -32, -13, -17, -121, 112, -29, 68, -50, 38, -100, 24, 61, 97, -124, -102, -75, -65, -101, 106, -74, 81, 37, -37, 84, -43, -69, 94, -90, 103, -126, -123, 126, 123, -104, 45, -99, 19, -5, 98, -28, -118, 46, 93, 12, 97, -67, 107, 110, 4, -120, 106, -90, -73, 68, 107, -22, -22, -126, 33, -125, -75, -120, -118, 14, 113, 98, -43, -92, 75, 91, -86, 19};
const int64_t p0_param_shape[6] = {1, 1, 5, 5, 3, 8};
const DLTensor p0_param = {
    (void*) p0_param_data,  // data
    {kDLCPU, 0},  // context
    6,  // ndim
    {0, 0, 0},  // dtype
    p0_param_shape,  // shape
    NULL,  // stride
    0  // byte_offset
};
int main_func(TVMValue* values, int* tcodes, int nargs, TVMValue* out_ret_value, int* out_ret_code, void* resource_handle) {
    uint8_t* sid_2;
    uint8_t* sid_3;
    sid_2 = TVMBackendAllocWorkspace(kDLCPU, 0, 600, kDLInt, 8);
    sid_3 = TVMBackendAllocWorkspace(kDLCPU, 0, 32768, kDLInt, 8);
    {
        TVMValue subcall_values[2] = {
            values[0], 
            values[1]
        };
        int subcall_tcodes[2] = {
            tcodes[0], 
            tcodes[1]
        };
        TVMValue subcall_ret_value;
        int subcall_ret_tcode;
        int rv;
        rv = fused_layout_transform_2(subcall_values, subcall_tcodes, 2, &subcall_ret_value, &subcall_ret_tcode, NULL);
        if (rv != 0) {
            return rv;
        }
    }
    {
         int64_t sid_3_tensor_shape[5] = {1, 1, 64, 64, 8};
         DLTensor sid_3_tensor = {
            (void*) sid_3,  // data
            {kDLCPU, 0},  // context
            5,  // ndim
            {0, 0, 0},  // dtype
            sid_3_tensor_shape,  // shape
            NULL,  // stride
            0  // byte_offset
        };
        TVMValue subcall_values[3] = {
            values[1], 
            &p0_param, 
            {.v_handle = &sid_3_tensor}
        };
        int subcall_tcodes[3] = {
            tcodes[1], 
            kTVMDLTensorHandle, 
            kTVMDLTensorHandle
        };
        TVMValue subcall_ret_value;
        int subcall_ret_tcode;
        int rv;
        rv = fused_nn_contrib_conv2d_NCHWc_right_shift_cast(subcall_values, subcall_tcodes, 3, &subcall_ret_value, &subcall_ret_tcode, NULL);
        if (rv != 0) {
            return rv;
        }
    }
    {
         int64_t sid_3_tensor_shape[5] = {1, 1, 64, 64, 8};
         DLTensor sid_3_tensor = {
            (void*) sid_3,  // data
            {kDLCPU, 0},  // context
            5,  // ndim
            {0, 0, 0},  // dtype
            sid_3_tensor_shape,  // shape
            NULL,  // stride
            0  // byte_offset
        };
        TVMValue subcall_values[2] = {
            {.v_handle = &sid_3_tensor}, 
            values[1]
        };
        int subcall_tcodes[2] = {
            kTVMDLTensorHandle, 
            tcodes[1]
        };
        TVMValue subcall_ret_value;
        int subcall_ret_tcode;
        int rv;
        rv = fused_layout_transform_1(subcall_values, subcall_tcodes, 2, &subcall_ret_value, &subcall_ret_tcode, NULL);
        if (rv != 0) {
            return rv;
        }
    }
    return 0;
}

all passed
